{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8194007-6ea7-4e00-8931-a37ca2d0dd20",
   "metadata": {
    "id": "f8194007-6ea7-4e00-8931-a37ca2d0dd20"
   },
   "source": "# Post-Training Quantization + Conversion to IMX500 of a MobileNetV2 Keras Model"
  },
  {
   "cell_type": "markdown",
   "id": "930e6d6d-4980-4d66-beed-9ff5a494acf9",
   "metadata": {
    "id": "930e6d6d-4980-4d66-beed-9ff5a494acf9"
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699be4fd-d382-4eec-9d3f-e2e85cfb1762",
   "metadata": {
    "id": "699be4fd-d382-4eec-9d3f-e2e85cfb1762"
   },
   "source": [
    "This tutorial demonstrates how to apply Post Training Quantization to a Keras pretrained model using the [**Model Compression Toolkit (MCT)**](https://github.com/sony/model_optimization) and how to convert the resulting model to a binary format suitable to load to IMX500 using the [**IMX500-converter**](https://developer.aitrios.sony-semicon.com/en/raspberrypi-ai-camera/documentation/imx500-converter?version=3.14.3&progLang=) . \n",
    "\n",
    "This example is not intended to demonstrate evaluating MCT PTQ performance and as such intentionally uses generated random data   to speed up the process.\n",
    " \n",
    "For the tutorial on MCT's PTQ  see - [*MCT PTQ Keras Tutorial*](https://github.com/sony/model_optimization/blob/main/tutorials/notebooks/imx500_notebooks/keras/example_keras_mobilenetv2_for_imx500.ipynb)\n",
    "\n",
    "For tutorials on other quantization features of MCT see [*MCT Features Tutorials*](https://github.com/sony/model_optimization/blob/main/tutorials/notebooks/mct_features_notebooks/README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85199e25-c587-41b1-aaf5-e1d23ce97ca1",
   "metadata": {
    "id": "85199e25-c587-41b1-aaf5-e1d23ce97ca1"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0e9543-d356-412f-acf1-c2ecad553e06",
   "metadata": {
    "id": "9c0e9543-d356-412f-acf1-c2ecad553e06"
   },
   "source": [
    "In this tutorial we cover the following steps:\n",
    "\n",
    "1. Post-Training Quantization using MCT.\n",
    "2. Converting the model to a IMX500 suitable representation using IMX500-Converter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04228b7c-00f1-4ded-bead-722e2a4e89a0",
   "metadata": {
    "tags": [],
    "id": "04228b7c-00f1-4ded-bead-722e2a4e89a0"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2657cf1a-654d-45a6-b877-8bf42fc26d0d",
   "metadata": {
    "id": "2657cf1a-654d-45a6-b877-8bf42fc26d0d"
   },
   "source": [
    "Install and import the relevant packages:\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from importlib import util\n",
    "TF_VER = '2.15.1'\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "except ImportError:\n",
    "    print(f\"Installing TensorFlow {TF_VER}\")\n",
    "    !pip install tensorflow=={TF_VER}\n",
    "\n",
    "if not util.find_spec('edge_mdt') or not util.find_spec(\"uni.tensorflow\"):\n",
    "    print(f\"Installing edge-mdt\")\n",
    "    !pip install edge-mdt[tf]\n"
   ],
   "id": "324685b9-5dcc-4d22-80f4-dec9a93d3324",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Post-Training quantization using MCT",
   "id": "48c6a7b1d26132f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Representative dataset construction\n",
    "We're all set to use MCT's post-training quantization. To begin, we'll define a representative dataset generator. Please note that for demonstration purposes, we will generate random data of the desired image shape instead of using real images.\n",
    "Then, we will apply PTQ on our model using the dataset generator we have created. For more details on using MCT, refer to the MCT tutorials"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcbb3eecae5346a9"
  },
  {
   "cell_type": "code",
   "id": "0408f624-ab68-4989-95f8-f9d327882840",
   "metadata": {
    "id": "0408f624-ab68-4989-95f8-f9d327882840"
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define batch size and iterations\n",
    "batch_size = 4\n",
    "n_iter = 2\n",
    "\n",
    "# Define representative dataset generator\n",
    "def representative_dataset_gen():\n",
    "    for _ in range(n_iter):\n",
    "        yield [np.random.rand(batch_size, 224, 224, 3).astype(np.float32)]  # Yield random batch"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4a1e9ba6-2954-4506-ad5c-0da273701ba5",
   "metadata": {
    "id": "4a1e9ba6-2954-4506-ad5c-0da273701ba5"
   },
   "source": [
    "## Model Post-Training quantization using MCT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55edbb99-ab2f-4dde-aa74-4ddee61b2615",
   "metadata": {
    "id": "55edbb99-ab2f-4dde-aa74-4ddee61b2615"
   },
   "source": [
    "Now we are ready to quantize our model.\n",
    "\n",
    "First, we load a pre-trained MobileNetV2 model from Keras, in 32-bits floating-point precision format."
   ]
  },
  {
   "cell_type": "code",
   "id": "80cac59f-ec5e-41ca-b673-96220924a47c",
   "metadata": {
    "id": "80cac59f-ec5e-41ca-b673-96220924a47c"
   },
   "source": [
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "float_model = MobileNetV2()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8a8b486a-ca39-45d9-8699-f7116b0414c9",
   "metadata": {
    "id": "8a8b486a-ca39-45d9-8699-f7116b0414c9"
   },
   "source": [
    "Next, we need to define a `TargetPlatformCapability` object, representing the HW specifications on which we wish to eventually deploy our quantized model.\n",
    "\n",
    "In addition, we need to define the Quantization Configuration for our PTQ routine.\n",
    "\n",
    "Here, we demonstrate how to define a quantization configuration with several key argument that can be controlled by the user.\n",
    "**Note** that you can skip this part if you prefer to use the default quantization settings."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import model_compression_toolkit as mct\n",
    "from edgemdt_tpc import get_target_platform_capabilities\n",
    "# Target platform capabilities\n",
    "tpc = get_target_platform_capabilities(tpc_version='1.0', device_type='imx500')\n",
    "\n",
    "# Perform Post-Training Quantization (PTQ)\n",
    "quantized_model, quantization_info = mct.ptq.keras_post_training_quantization(\n",
    "    in_model=float_model,\n",
    "    representative_data_gen=representative_dataset_gen,\n",
    "    target_platform_capabilities=tpc\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2edacb5b7779e4d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7382ada6-d001-4564-907d-767fa4e9ec56",
   "metadata": {
    "id": "7382ada6-d001-4564-907d-767fa4e9ec56"
   },
   "source": [
    "That's it! Our model is now quantized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7a5150-3b92-49b5-abb2-06e6c5c91d6b",
   "metadata": {
    "id": "5a7a5150-3b92-49b5-abb2-06e6c5c91d6b"
   },
   "source": [
    "## Model Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce4fc61-e13c-48be-9f7c-d441ad76a386",
   "metadata": {
    "id": "0ce4fc61-e13c-48be-9f7c-d441ad76a386"
   },
   "source": [
    "### Exporting to Keras serialization\n",
    " In order to convert our model to an binary suitable to load to IMX500, we first need to serialize it to Keras format. Please ensure that the `save_model_path` has been set correctly."
   ]
  },
  {
   "cell_type": "code",
   "id": "eef7c875-c4fc-4819-97e5-721805cba546",
   "metadata": {
    "tags": [],
    "id": "eef7c875-c4fc-4819-97e5-721805cba546"
   },
   "source": [
    "save_folder=\"./mobilenet_tf\"\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "keras_path = os.path.join(save_folder, 'qmodel.keras')\n",
    "mct.exporter.keras_export_model(model=quantized_model, save_model_path=keras_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "before we can run the IMX500 converter we need to make sure java 17 or up is installed. for colab you can use this dist",
   "metadata": {
    "id": "6YjIdiRRjgkL"
   },
   "id": "6YjIdiRRjgkL"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!sudo apt install -y openjdk-17-jre",
   "id": "9500d173406cf04f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Running the IMX500 Converter\n",
    " Now, we can convert the model to create the PackerOut which can be loaded to IMX500"
   ],
   "id": "58b62a9c774ecf9e"
  },
  {
   "cell_type": "code",
   "source": "!imxconv-tf -i {keras_path} -o {save_folder} --overwrite-output",
   "metadata": {
    "id": "z3CA16-ojoFL"
   },
   "id": "z3CA16-ojoFL",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "14877777",
   "metadata": {
    "id": "14877777"
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7e1572",
   "metadata": {
    "id": "bb7e1572"
   },
   "source": [
    "In this tutorial, we demonstrated how to quantize a pre-trained model using MCT then convert it to a binary suitable for IMX500 execution, all with a few lines of code. for full documentation of the IMX500 converter see [here](https://developer.aitrios.sony-semicon.com/en/raspberrypi-ai-camera/documentation/imx500-converter?version=3.14.3&progLang=).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c1645e-205c-4d9a-8af3-e497b3addec1",
   "metadata": {
    "id": "01c1645e-205c-4d9a-8af3-e497b3addec1"
   },
   "source": [
    "\n",
    "\n",
    "Copyright 2025 Sony Semiconductor Solutions, Inc. All rights reserved.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
